{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcoVsJCol0uC"
      },
      "source": [
        "**Gradient Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mTlGrOOqkgj3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [ 4.95252513e+10  2.12031114e-02  4.95931889e+02  1.41678144e-04 -6.53959781e-06 -4.79261075e-12  5.32096364e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.95252513e+10  2.80453750e-02  4.52765860e+02  1.29243572e-04 -3.32601440e-05 -7.16893211e-12  5.35031710e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.95060958e+10  3.73409941e-02  4.10603427e+02  1.17683767e-04 -2.28150797e-07 -8.69437855e-12  5.35971859e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.97738272e+10  5.43008004e-02  3.69471113e+02  1.06802338e-04 -3.97881342e-06 -9.98001681e-12  5.37680015e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.01890334e+10  6.89385073e-02  3.34120669e+02  9.73293788e-05 -1.07990401e-05 -9.95625804e-12  5.39080153e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import RobustScaler, PowerTransformer\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = RobustScaler()\n",
        "\n",
        "# Target transformations\n",
        "target_transformer = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# For each target variable\n",
        "output_transformers = {}\n",
        "for i in range(y.shape[1]):\n",
        "    output_transformers[i] = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Preprocessing\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "\n",
        "# Transform each target separately\n",
        "y_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_transformed[:, i] = output_transformers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Model pipeline\n",
        "gb_model = MultiOutputRegressor(GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        "))\n",
        "\n",
        "# Train\n",
        "gb_model.fit(X_scaled, y_transformed)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_transformed = gb_model.predict(X_scaled)\n",
        "y_pred = np.zeros_like(y_pred_transformed)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = output_transformers[i].inverse_transform(y_pred_transformed[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaJqaKA5ltLy",
        "outputId": "d12c0913-0c23-4400-b4dc-1029366b8b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 2538691730.975251\n",
            "  MSE: 6.275206071783603e+19\n",
            "  R²: 0.9991881156970343\n",
            "Target 2:\n",
            "  MAE: 0.15953151412712088\n",
            "  MSE: 0.2545383955859068\n",
            "  R²: 0.9999697528600925\n",
            "Target 3:\n",
            "  MAE: 3.7912886551165443\n",
            "  MSE: 183.0489944073925\n",
            "  R²: 0.9989915695636539\n",
            "Target 4:\n",
            "  MAE: 2.051707835873977e-06\n",
            "  MSE: 2.8144161104170293e-11\n",
            "  R²: 0.9999768638506548\n",
            "Target 5:\n",
            "  MAE: 0.0020339600760367047\n",
            "  MSE: 0.0009571000968851482\n",
            "  R²: 0.9926139110506323\n",
            "Target 6:\n",
            "  MAE: 9.32641161408819e-11\n",
            "  MSE: 9.140428866049495e-20\n",
            "  R²: 0.9998612196511251\n",
            "Target 7:\n",
            "  MAE: 5.335547741434522\n",
            "  MSE: 57.13443436161579\n",
            "  R²: 0.9999728684379342\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 362670248.60909367\n",
            "  Average MSE: 8.964580102548005e+18\n",
            "  Average R²: 0.998653471587304\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'GradientBoostingRegressor'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_LDRnW0mEEc"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH4LxwExmAJZ",
        "outputId": "af10d0a9-5f48-4163-ce59-40045b3eb2c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "Predicted: [ 4.3764990e+10  2.5326817e+00 -4.7346306e+00  6.7365303e-04  7.4888994e-06 -3.0149292e-09  6.0475752e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.3703927e+10  2.4387929e+00 -1.7985158e+00  6.7344279e-04  6.6845955e-06 -2.8861264e-09  6.0328984e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.3751674e+10  2.3712888e+00  1.2550834e+00  6.7452498e-04  6.1288920e-06 -2.7927856e-09  6.0115527e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.3800134e+10  2.3044260e+00  4.3102093e+00  6.7563239e-04  5.5787818e-06 -2.7002354e-09  5.9901211e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.3845190e+10  2.2381225e+00  7.3530350e+00  6.7676499e-04  5.0344297e-06 -2.6086691e-09  5.9689150e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = RobustScaler()\n",
        "target_scaler = RobustScaler()\n",
        "\n",
        "# Preprocessing\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "y_scaled = target_scaler.fit_transform(y)\n",
        "\n",
        "# Define model\n",
        "nn_model = Sequential([\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(y.shape[1], activation='linear')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "nn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(patience=20, restore_best_weights=True)\n",
        "\n",
        "# Train\n",
        "nn_model.fit(\n",
        "    X_scaled, y_scaled,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_scaled = nn_model.predict(X_scaled)\n",
        "y_pred = target_scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTadEIC2mHcR",
        "outputId": "c1485ba2-e7fc-45ea-9e44-85c54c7ce03e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 81958763796.03078\n",
            "  MSE: 8.611194351637371e+22\n",
            "  R²: -0.11411377473616247\n",
            "Target 2:\n",
            "  MAE: 14.755620079050608\n",
            "  MSE: 8375.15507233397\n",
            "  R²: 0.004769057978232016\n",
            "Target 3:\n",
            "  MAE: 173.85156307678778\n",
            "  MSE: 456771.6884196564\n",
            "  R²: -1.516388984024759\n",
            "Target 4:\n",
            "  MAE: 0.0008796226837980667\n",
            "  MSE: 1.4341710482853959e-06\n",
            "  R²: -0.17897262728714036\n",
            "Target 5:\n",
            "  MAE: 0.05532649217292052\n",
            "  MSE: 0.12974732706775927\n",
            "  R²: -0.0012801187503812539\n",
            "Target 6:\n",
            "  MAE: 8.254639116797784e-09\n",
            "  MSE: 6.202432183551563e-16\n",
            "  R²: 0.05827646063368086\n",
            "Target 7:\n",
            "  MAE: 1176.131694826555\n",
            "  MSE: 3485253.81387252\n",
            "  R²: -0.6550506051667022\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 11708395022.975124\n",
            "  Average MSE: 1.2301706216624817e+22\n",
            "  Average R²: -0.34325151305046175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'NeuralNetwork'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_nH9vKSpSn6"
      },
      "source": [
        "**Random Forest with Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fDIaXl-_pR8x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [ 4.76841837e+10  2.03740775e-02  4.95953663e+02  1.42297792e-04  6.57952359e-10 -5.94924110e-12  5.33318379e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.81837559e+10  2.86249649e-02  4.49478256e+02  1.29391463e-04  6.57952359e-10 -7.53686002e-12  5.33772044e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.87530239e+10  4.32669430e-02  4.08749136e+02  1.17968211e-04  6.57952359e-10 -1.01965103e-11  5.35543246e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.96252325e+10  5.65690322e-02  3.71600082e+02  1.07761690e-04  6.57952359e-10 -1.14221965e-11  5.38063090e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.03678071e+10  7.12235237e-02  3.37443241e+02  9.84027769e-05  6.57952359e-10 -1.37139189e-11  5.39432543e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "\n",
        "# Feature engineering\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "feature_scaler = RobustScaler()\n",
        "\n",
        "# Target transformations\n",
        "target_transformer = {}\n",
        "for i in range(y.shape[1]):\n",
        "    target_transformer[i] = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Preprocessing\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_scaled = feature_scaler.fit_transform(X_poly)\n",
        "\n",
        "# Transform targets\n",
        "y_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_transformed[:, i] = target_transformer[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Model\n",
        "rf_model = MultiOutputRegressor(RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        "))\n",
        "\n",
        "# Train\n",
        "rf_model.fit(X_scaled, y_transformed)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_transformed = rf_model.predict(X_scaled)\n",
        "y_pred = np.zeros_like(y_pred_transformed)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = target_transformer[i].inverse_transform(y_pred_transformed[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E-BxJ9Hp0WN",
        "outputId": "113faea6-45b9-4cac-feda-318c3d2e3e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 17736060587.119816\n",
            "  MSE: 2.7729074834363327e+22\n",
            "  R²: 0.6412420510776202\n",
            "Target 2:\n",
            "  MAE: 4.947719460255993\n",
            "  MSE: 1945.129652501506\n",
            "  R²: 0.7688576271490972\n",
            "Target 3:\n",
            "  MAE: 11.885805841702211\n",
            "  MSE: 8197.491960189553\n",
            "  R²: 0.9548394110488289\n",
            "Target 4:\n",
            "  MAE: 1.7767391096939292e-06\n",
            "  MSE: 1.4576658858053153e-10\n",
            "  R²: 0.999880171323975\n",
            "Target 5:\n",
            "  MAE: 0.010821888736867648\n",
            "  MSE: 0.016794749080189617\n",
            "  R²: 0.8703923330565955\n",
            "Target 6:\n",
            "  MAE: 1.3093656265603795e-09\n",
            "  MSE: 1.320879634603557e-16\n",
            "  R²: 0.7994490858159641\n",
            "Target 7:\n",
            "  MAE: 20.970984796329358\n",
            "  MSE: 2419.962606460625\n",
            "  R²: 0.9988508267144386\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 2533722946.419307\n",
            "  Average MSE: 3.961296404909047e+21\n",
            "  Average R²: 0.8619302151695027\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'RandomForestRegressor'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oikWyUtaqCit"
      },
      "source": [
        "**XGBoost with Custom Objective**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WRcZg_pGqBqj"
      },
      "outputs": [
        {
          "ename": "XGBoostError",
          "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <54A1AE05-1E14-3DA2-A8D0-062134694298> /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/lib/python3.12/lib-dynload/../../libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/bin/../lib/libomp.dylib' (no such file)\"]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load Data (replace this with actual CSV file or DataFrame)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/core.py:295\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/core.py:257\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    256\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    258\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    266\u001b[39m \n\u001b[32m    267\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    268\u001b[39m \n\u001b[32m    269\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    271\u001b[39m         )\n\u001b[32m    272\u001b[39m     _register_log_callback(lib)\n\u001b[32m    274\u001b[39m     libver = _lib_version(lib)\n",
            "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <54A1AE05-1E14-3DA2-A8D0-062134694298> /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/lib/python3.12/lib-dynload/../../libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/bin/../lib/libomp.dylib' (no such file)\"]\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = RobustScaler()\n",
        "target_scalers = [RobustScaler() for _ in range(y.shape[1])]\n",
        "\n",
        "# Preprocess\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "y_scaled = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_scaled[:, i] = target_scalers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Train separate models for each output\n",
        "xgb_models = []\n",
        "for i in range(y.shape[1]):\n",
        "    dtrain = xgb.DMatrix(X_scaled, label=y_scaled[:, i])\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eta': 0.1,\n",
        "        'max_depth': 6,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8\n",
        "    }\n",
        "    model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "    xgb_models.append(model)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_scaled = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    dtest = xgb.DMatrix(X_scaled)\n",
        "    y_pred_scaled[:, i] = xgb_models[i].predict(dtest)\n",
        "\n",
        "y_pred = np.zeros_like(y_pred_scaled)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = target_scalers[i].inverse_transform(y_pred_scaled[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ohrleqqW4A",
        "outputId": "4048488e-7be0-4085-9d0c-9a6d74bd660a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 17736060587.119816\n",
            "  MSE: 2.7729074834363327e+22\n",
            "  R²: 0.6412420510776202\n",
            "Target 2:\n",
            "  MAE: 4.947719460255993\n",
            "  MSE: 1945.129652501506\n",
            "  R²: 0.7688576271490972\n",
            "Target 3:\n",
            "  MAE: 11.885805841702211\n",
            "  MSE: 8197.491960189553\n",
            "  R²: 0.9548394110488289\n",
            "Target 4:\n",
            "  MAE: 1.7767391096939292e-06\n",
            "  MSE: 1.4576658858053153e-10\n",
            "  R²: 0.999880171323975\n",
            "Target 5:\n",
            "  MAE: 0.010821888736867648\n",
            "  MSE: 0.016794749080189617\n",
            "  R²: 0.8703923330565955\n",
            "Target 6:\n",
            "  MAE: 1.3093656265603795e-09\n",
            "  MSE: 1.320879634603557e-16\n",
            "  R²: 0.7994490858159641\n",
            "Target 7:\n",
            "  MAE: 20.970984796329358\n",
            "  MSE: 2419.962606460625\n",
            "  R²: 0.9988508267144386\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 2533722946.419307\n",
            "  Average MSE: 3.961296404909047e+21\n",
            "  Average R²: 0.8619302151695027\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'XGBoost'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmHQ9VOyqeff"
      },
      "source": [
        "**Transformer Model for Time Series Properties**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQO52Yx4qlDg",
        "outputId": "a8a6b799-0f39-425c-c798-3d6fc1549a63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/keras/src/ops/nn.py:908: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Predicted: [5.4461436e+10 1.6134955e-01 4.2003253e+02 7.3577242e-04 7.9252681e-11 3.2005180e-11 5.2433730e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.4870790e+10  1.4926365e-01  4.1573822e+02  6.1308179e-04 -6.8304357e-13  3.2176085e-11  5.2667866e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.4857466e+10  1.3418195e-01  4.0726968e+02  5.0456583e-04 -7.0301605e-11  4.3088946e-11  5.2924146e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.4664462e+10  1.1815179e-01  3.9697284e+02  3.9314784e-04 -1.3995405e-10  5.6796647e-11  5.3201660e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.4438687e+10  1.0651932e-01  3.8476028e+02  3.0183149e-04 -1.9085139e-10  6.8275725e-11  5.3448901e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/keras/src/ops/nn.py:908: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, MultiHeadAttention, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = RobustScaler()\n",
        "target_scaler = RobustScaler()\n",
        "\n",
        "# Preprocess\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "y_scaled = target_scaler.fit_transform(y)\n",
        "\n",
        "# Convert 2D data to 3D by treating each sample as a sequence of features\n",
        "X_3d = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
        "\n",
        "# Define Transformer Model\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head attention\n",
        "    attention_output = MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(inputs, inputs)\n",
        "    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
        "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
        "    ffn_output = LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)\n",
        "\n",
        "    return ffn_output\n",
        "\n",
        "# Build the model\n",
        "inputs = Input(shape=(1, X.shape[1]))\n",
        "x = transformer_encoder(inputs, head_size=16, num_heads=2, ff_dim=32, dropout=0.1)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = Dense(32, activation=\"relu\")(x)\n",
        "outputs = Dense(y.shape[1])(x)\n",
        "\n",
        "transformer_model = Model(inputs=inputs, outputs=outputs)\n",
        "transformer_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train\n",
        "transformer_model.fit(\n",
        "    X_3d, y_scaled,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_scaled = transformer_model.predict(X_3d)\n",
        "y_pred = target_scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgDQTfQqq5yh",
        "outputId": "f52df91e-ba0a-4ebd-e5db-8a40d83f315e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 42065830729.26874\n",
            "  MSE: 7.165271866049694e+22\n",
            "  R²: 0.07295924819330768\n",
            "Target 2:\n",
            "  MAE: 13.192160335660914\n",
            "  MSE: 8368.218899405729\n",
            "  R²: 0.005593292736607247\n",
            "Target 3:\n",
            "  MAE: 114.4721857119104\n",
            "  MSE: 172435.03518631298\n",
            "  R²: 0.05004264930688085\n",
            "Target 4:\n",
            "  MAE: 0.00021341387620981244\n",
            "  MSE: 9.316860103498646e-08\n",
            "  R²: 0.9234099513623518\n",
            "Target 5:\n",
            "  MAE: 0.05534829666124632\n",
            "  MSE: 0.1297734788849429\n",
            "  R²: -0.0014819363539257946\n",
            "Target 6:\n",
            "  MAE: 5.80512866967703e-09\n",
            "  MSE: 5.747225875368768e-16\n",
            "  R²: 0.1273910406883575\n",
            "Target 7:\n",
            "  MAE: 602.510003224058\n",
            "  MSE: 787533.5878438124\n",
            "  R²: 0.6260220888470188\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 6009404494.214093\n",
            "  Average MSE: 1.0236102665785278e+22\n",
            "  Average R²: 0.25770519068294256\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'Transformer'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNTKB6uqrTO1"
      },
      "source": [
        "**Stacked Model with Different Base Learners**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "S4dVenUSrN5C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [ 4.16594797e+10  3.53714626e+00  4.78233025e+02  1.01545074e-04  9.00985268e-03 -1.18999988e-09  5.28776962e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.20502945e+10  3.54207461e+00  4.54047537e+02  9.04697414e-05  9.01032790e-03 -1.17589360e-09  5.27513785e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.26179428e+10  3.54704423e+00  4.13781048e+02  7.84136474e-05  9.01353744e-03 -1.17348509e-09  5.28300131e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.30917955e+10  3.55150843e+00  3.83007637e+02  6.88954746e-05  9.03175899e-03 -1.17324461e-09  5.34540505e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.37862768e+10  3.54951754e+00  3.48675924e+02  6.06760126e-05  9.03706330e-03 -1.17731647e-09  5.37950753e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = RobustScaler()\n",
        "target_transformers = {}\n",
        "for i in range(y.shape[1]):\n",
        "    target_transformers[i] = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Preprocess features\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "\n",
        "# Transform targets\n",
        "y_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_transformed[:, i] = target_transformers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Base models for stacking\n",
        "estimators = [\n",
        "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('gbr', GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
        "    ('en', ElasticNet(random_state=42))\n",
        "]\n",
        "\n",
        "# Stacked models for each output\n",
        "stacked_models = []\n",
        "for i in range(y.shape[1]):\n",
        "    # Create stacking regressor\n",
        "    stacked_model = StackingRegressor(\n",
        "        estimators=estimators,\n",
        "        final_estimator=SVR(kernel='rbf'),\n",
        "        cv=5\n",
        "    )\n",
        "    # Train\n",
        "    stacked_model.fit(X_scaled, y_transformed[:, i])\n",
        "    stacked_models.append(stacked_model)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred_transformed[:, i] = stacked_models[i].predict(X_scaled)\n",
        "\n",
        "y_pred = np.zeros_like(y_pred_transformed)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = target_transformers[i].inverse_transform(y_pred_transformed[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687anEaLrfQb",
        "outputId": "75de6c0c-46d1-4bb8-bbc6-2d015bf2ce65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 31046276415.322464\n",
            "  MSE: 6.704429072309565e+22\n",
            "  R²: 0.13258295235417683\n",
            "Target 2:\n",
            "  MAE: 12.191703856724741\n",
            "  MSE: 7901.68363715561\n",
            "  R²: 0.06103230545045357\n",
            "Target 3:\n",
            "  MAE: 66.6666481734622\n",
            "  MSE: 180994.4175596139\n",
            "  R²: 0.002888379328480739\n",
            "Target 4:\n",
            "  MAE: 8.444626148340269e-05\n",
            "  MSE: 3.202069394203956e-08\n",
            "  R²: 0.9736771135426718\n",
            "Target 5:\n",
            "  MAE: 0.046902841993351076\n",
            "  MSE: 0.13247394678586036\n",
            "  R²: -0.022321863322904312\n",
            "Target 6:\n",
            "  MAE: 3.9919456879571465e-09\n",
            "  MSE: 4.3241901830208627e-16\n",
            "  R²: 0.3434524451800248\n",
            "Target 7:\n",
            "  MAE: 212.71456872399685\n",
            "  MSE: 514123.5889203161\n",
            "  R²: 0.7558569325464428\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 4435182386.706053\n",
            "  Average MSE: 9.577755817585093e+21\n",
            "  Average R²: 0.32102403786847805\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'StackingRegressor'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv1vCpplrsEG"
      },
      "source": [
        "**Support Vector Regression with RBF Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "w7sa5_8FrniQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [ 4.33495997e+11 -6.67025712e+01  5.04721190e+02  6.04056778e-04  2.16787282e-02  2.77597574e-08  5.90822875e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.53586095e+11 -5.35379107e+01  4.96742450e+02  5.58315678e-04  2.16345798e-02  2.43148182e-08  5.93303317e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.76382278e+11 -4.04119919e+01  4.87892233e+02  5.13741178e-04  2.08741428e-02  2.07065233e-08  5.95871831e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.01697281e+11 -2.75029682e+01  4.78128903e+02  4.70679718e-04  1.93004509e-02  1.69663784e-08  5.98511666e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 5.29309312e+11 -1.49929877e+01  4.67398371e+02  4.29473092e-04  1.68059892e-02  1.31285123e-08  6.01204755e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = MinMaxScaler()  # SVR works better with [0,1] scaling\n",
        "target_scalers = [MinMaxScaler() for _ in range(y.shape[1])]\n",
        "\n",
        "# Preprocess\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "y_scaled = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_scaled[:, i] = target_scalers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Create SVR model\n",
        "svr_model = MultiOutputRegressor(SVR(\n",
        "    kernel='rbf',\n",
        "    C=10.0,\n",
        "    epsilon=0.1,\n",
        "    gamma='scale'\n",
        "))\n",
        "\n",
        "# Train\n",
        "svr_model.fit(X_scaled, y_scaled)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_scaled = svr_model.predict(X_scaled)\n",
        "y_pred = np.zeros_like(y_pred_scaled)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = target_scalers[i].inverse_transform(y_pred_scaled[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykSmexDSr75g",
        "outputId": "efb695d9-635b-4a54-e84c-ad6821fc4403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 630200292725.166\n",
            "  MSE: 4.6250869347332626e+23\n",
            "  R²: -4.983923777494108\n",
            "Target 2:\n",
            "  MAE: 74.01372351936517\n",
            "  MSE: 15388.788905032345\n",
            "  R²: -0.8286704838602361\n",
            "Target 3:\n",
            "  MAE: 210.73074061308026\n",
            "  MSE: 87601.25955055548\n",
            "  R²: 0.5173981879604049\n",
            "Target 4:\n",
            "  MAE: 0.00025718312154098633\n",
            "  MSE: 8.751368111816894e-08\n",
            "  R²: 0.9280586268459348\n",
            "Target 5:\n",
            "  MAE: 0.24315491976164708\n",
            "  MSE: 0.09239163492133329\n",
            "  R²: 0.2869995145467462\n",
            "Target 6:\n",
            "  MAE: 1.601291689043629e-08\n",
            "  MSE: 8.489888038282431e-16\n",
            "  R²: -0.28903100842241414\n",
            "Target 7:\n",
            "  MAE: 347.2037367187923\n",
            "  MSE: 165944.09465824167\n",
            "  R²: 0.9211977408374743\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 90028613336.76537\n",
            "  Average MSE: 6.607267049618946e+22\n",
            "  Average R²: -0.4925673142265999\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'SupportVectorRegressor'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD2gQYbnvU6i"
      },
      "source": [
        "**Multi-Task Lasso with Polynomial Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTCqMYPnuubz",
        "outputId": "95ac708d-4f7b-47e3-ae6c-8958eb5fa099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [-9.24547202e+09 -2.78102877e+01  4.87191778e+02  1.56044897e-04  9.23998293e-03  5.39206942e-09  5.31956805e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [-9.30285938e+09 -2.76559042e+01  4.25421419e+02  1.30619796e-04 -8.86000078e-03  6.10405763e-09  5.33959574e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [-6.81145156e+09 -2.61365766e+01  3.73479979e+02  1.10119240e-04 -2.06239138e-02  6.29579464e-09  5.35962731e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [-2.09662135e+09 -2.34616391e+01  3.30302860e+02  9.39862246e-05 -2.68834109e-02  6.03936081e-09  5.37966270e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 4.51625849e+09 -1.98404261e+01  2.94825468e+02  8.16637470e-05 -2.84701468e-02  5.40683650e-09  5.39970186e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:2637: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.345830855867261e+18, tolerance: 6542470679760704.0\n",
            "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import MultiTaskLasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "\n",
        "# Feature engineering\n",
        "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
        "feature_scaler = RobustScaler()\n",
        "target_scaler = RobustScaler()\n",
        "\n",
        "# Preprocess\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_scaled = feature_scaler.fit_transform(X_poly)\n",
        "y_scaled = target_scaler.fit_transform(y)\n",
        "\n",
        "# Define model\n",
        "mtl_model = MultiTaskLasso(\n",
        "    alpha=0.1,\n",
        "    max_iter=10000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train\n",
        "mtl_model.fit(X_scaled, y_scaled)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_scaled = mtl_model.predict(X_scaled)\n",
        "y_pred = target_scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbROCLfuvgCi",
        "outputId": "0b9e1793-f51e-4ec0-8896-4a7dd3b64c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 70201893695.53142\n",
            "  MSE: 6.366160124537224e+22\n",
            "  R²: 0.17634808862787066\n",
            "Target 2:\n",
            "  MAE: 23.446047456457723\n",
            "  MSE: 7662.550075493771\n",
            "  R²: 0.0894488682228739\n",
            "Target 3:\n",
            "  MAE: 88.5219590301462\n",
            "  MSE: 45525.703464258826\n",
            "  R²: 0.7491955355556383\n",
            "Target 4:\n",
            "  MAE: 1.1381383163193892e-05\n",
            "  MSE: 4.873936614224665e-10\n",
            "  R²: 0.9995993338547606\n",
            "Target 5:\n",
            "  MAE: 0.07421471935489946\n",
            "  MSE: 0.033059826267002344\n",
            "  R²: 0.7448722257437812\n",
            "Target 6:\n",
            "  MAE: 5.41656006638848e-09\n",
            "  MSE: 4.754836324536006e-16\n",
            "  R²: 0.27806686794186\n",
            "Target 7:\n",
            "  MAE: 0.9956746762154437\n",
            "  MSE: 3.489762368188492\n",
            "  R²: 0.9999983428084072\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 10028841972.652761\n",
            "  Average MSE: 9.094514463624607e+21\n",
            "  Average R²: 0.576789894679313\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "model_name = 'MultiTaskLasso'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7RNQMXZvyGQ"
      },
      "source": [
        "**Bayesian Ridge Regression with Custom Basis Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XYc-1eQRvxk9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [ 8.46935102e+10  5.09327954e+00  8.23552117e+01  4.69812337e-04  1.95466541e-02 -4.40034253e-09  6.00444442e+03]\n",
            "Actual:    [ 4.76657088e+10  1.58911049e-02  4.96356224e+02  1.42281371e-04  9.72737333e-11 -4.04666773e-12  5.32000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 8.46935102e+10  5.09327954e+00  8.23552117e+01  4.69812337e-04  1.95466541e-02 -4.40034253e-09  6.00444442e+03]\n",
            "Actual:    [ 4.82809038e+10  2.72979275e-02  4.49900677e+02  1.29409565e-04  1.07791406e-10 -6.69366364e-12  5.34000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 8.46935102e+10  5.09327954e+00  8.23552117e+01  4.69812337e-04  1.95466541e-02 -4.40034253e-09  6.00444442e+03]\n",
            "Actual:    [ 4.89392674e+10  3.92584247e-02  4.09485667e+02  1.18222423e-04  1.18891373e-10 -9.06587901e-12  5.36000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 8.46935102e+10  5.09327954e+00  8.23552117e+01  4.69812337e-04  1.95466541e-02 -4.40034253e-09  6.00444442e+03]\n",
            "Actual:    [ 4.96214960e+10  5.24533488e-02  3.72497082e+02  1.07990927e-04  1.31107373e-10 -1.12797158e-11  5.38000000e+03]\n",
            "--------------------------------------------------\n",
            "Predicted: [ 8.46935102e+10  5.09327954e+00  8.23552117e+01  4.69812337e-04  1.95466541e-02 -4.40034253e-09  6.00444442e+03]\n",
            "Actual:    [ 5.03198510e+10  6.73510059e-02  3.38035646e+02  9.84642166e-05  1.44821296e-10 -1.33740120e-11  5.40000000e+03]\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import ARDRegression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.preprocessing import FunctionTransformer, RobustScaler, PowerTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Custom feature transformations - using physics-inspired basis functions\n",
        "def custom_basis_functions(X):\n",
        "    # Original features\n",
        "    features = X.copy()\n",
        "\n",
        "    # Add squared volume fraction (vf^2) - important for composite properties\n",
        "    features = np.column_stack((features, X[:, 0]**2))\n",
        "\n",
        "    # Add exponential decay related to volume fraction\n",
        "    features = np.column_stack((features, np.exp(-X[:, 0])))\n",
        "\n",
        "    # Add interaction between volume fraction and each material property\n",
        "    for i in range(1, X.shape[1]):\n",
        "        features = np.column_stack((features, X[:, 0] * X[:, i]))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Create transformer\n",
        "basis_transformer = FunctionTransformer(custom_basis_functions)\n",
        "\n",
        "# Feature scaling\n",
        "feature_scaler = RobustScaler()\n",
        "target_transformers = {}\n",
        "for i in range(y.shape[1]):\n",
        "    target_transformers[i] = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Preprocess\n",
        "X_basis = basis_transformer.fit_transform(X)\n",
        "X_scaled = feature_scaler.fit_transform(X_basis)\n",
        "\n",
        "# Transform targets\n",
        "y_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_transformed[:, i] = target_transformers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Model\n",
        "ard_model = MultiOutputRegressor(ARDRegression(\n",
        "    tol=1e-4,\n",
        "    alpha_1=1e-6,\n",
        "    alpha_2=1e-6,\n",
        "    lambda_1=1e-6,\n",
        "    lambda_2=1e-6\n",
        "))\n",
        "\n",
        "# Train\n",
        "ard_model.fit(X_scaled, y_transformed)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_transformed = ard_model.predict(X_scaled)\n",
        "y_pred = np.zeros_like(y_pred_transformed)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = target_transformers[i].inverse_transform(y_pred_transformed[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "\n",
        "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {y_pred[i]}\")\n",
        "    print(f\"Actual:    {y[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrEdsuZCxt-d",
        "outputId": "1a681097-6ee2-41ef-bbf4-27704a1a7f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 89230754914.82697\n",
            "  MSE: 7.742998139515294e+22\n",
            "  R²: -0.0017868059556882532\n",
            "Target 2:\n",
            "  MAE: 16.02361095370023\n",
            "  MSE: 8416.77169307311\n",
            "  R²: -0.00017630103951260523\n",
            "Target 3:\n",
            "  MAE: 144.79582829434295\n",
            "  MSE: 183385.9375816095\n",
            "  R²: -0.010286681190803115\n",
            "Target 4:\n",
            "  MAE: 0.0007734085581937731\n",
            "  MSE: 1.332981008065628e-06\n",
            "  R²: -0.09578848567737985\n",
            "Target 5:\n",
            "  MAE: 0.06801132940515982\n",
            "  MSE: 0.13069737796699848\n",
            "  R²: -0.008611807955140938\n",
            "Target 6:\n",
            "  MAE: 9.624209413854393e-09\n",
            "  MSE: 6.586286880124984e-16\n",
            "  R²: -4.709198073493681e-06\n",
            "Target 7:\n",
            "  MAE: 1173.4864399204766\n",
            "  MSE: 2106282.1127194623\n",
            "  R²: -0.00021509808916708728\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 12747250892.743088\n",
            "  Average MSE: 1.1061425913593277e+22\n",
            "  Average R²: -0.016695698443680764\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "model_name = 'BayesianRegression'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE2M0exbsEON"
      },
      "source": [
        "**CatBoost Regressor with Feature Interactions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_eazGhQzQKD",
        "outputId": "08bd5a8b-f7bb-4633-dea8-89869b6b2021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: catboost in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from catboost) (3.10.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from catboost) (2.2.3)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from catboost) (6.0.1)\n",
            "Requirement already satisfied: six in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages (from plotly->catboost) (1.31.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7SvOciVhsAe3"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load Data (replace this with actual CSV file or DataFrame)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/catboost/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[32m      3\u001b[39m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[32m      4\u001b[39m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[32m      5\u001b[39m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[32m      6\u001b[39m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      8\u001b[39m __all__ = [\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFeaturesData\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEFstrType\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEShapCalcType\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEFeaturesSelectionAlgorithm\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEFeaturesSelectionGrouping\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPool\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoost\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoostClassifier\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoostRegressor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoostRanker\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatboostError\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMultiTargetCustomMetric\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMultiTargetCustomObjective\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     14\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/catboost/core.py:45\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplot_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/catboost/plot_helpers.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[32m      6\u001b[39m fspath = _catboost.fspath\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtry_plot_offline\u001b[39m(figs):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:1\u001b[39m, in \u001b[36minit _catboost\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Load Data (replace this with actual CSV file or DataFrame)\n",
        "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "# Features and targets\n",
        "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
        "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
        "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
        "\n",
        "# Feature scaling - CatBoost handles scaling internally\n",
        "target_transformers = {}\n",
        "for i in range(y.shape[1]):\n",
        "    target_transformers[i] = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Transform targets only\n",
        "y_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_transformed[:, i] = target_transformers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
        "\n",
        "# Train separate models for each output\n",
        "catboost_models = []\n",
        "for i in range(y.shape[1]):\n",
        "    model = CatBoostRegressor(\n",
        "        iterations=500,\n",
        "        learning_rate=0.1,\n",
        "        depth=6,\n",
        "        loss_function='RMSE',\n",
        "        #feature_interactions='Quadratic',  # Enable feature interactions\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    model.fit(X, y_transformed[:, i])\n",
        "    catboost_models.append(model)\n",
        "\n",
        "# Predict and inverse transform\n",
        "y_pred_transformed = np.zeros_like(y)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred_transformed[:, i] = catboost_models[i].predict(X)\n",
        "\n",
        "y_pred = np.zeros_like(y_pred_transformed)\n",
        "for i in range(y.shape[1]):\n",
        "    y_pred[:, i] = target_transformers[i].inverse_transform(y_pred_transformed[:, i].reshape(-1, 1)).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enu-6CQqymCz",
        "outputId": "862ddbe7-b684-4346-9921-c56dbef40356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target 1:\n",
            "  MAE: 89230754914.82697\n",
            "  MSE: 7.742998139515294e+22\n",
            "  R²: -0.0017868059556882532\n",
            "Target 2:\n",
            "  MAE: 16.02361095370023\n",
            "  MSE: 8416.77169307311\n",
            "  R²: -0.00017630103951260523\n",
            "Target 3:\n",
            "  MAE: 144.79582829434295\n",
            "  MSE: 183385.9375816095\n",
            "  R²: -0.010286681190803115\n",
            "Target 4:\n",
            "  MAE: 0.0007734085581937731\n",
            "  MSE: 1.332981008065628e-06\n",
            "  R²: -0.09578848567737985\n",
            "Target 5:\n",
            "  MAE: 0.06801132940515982\n",
            "  MSE: 0.13069737796699848\n",
            "  R²: -0.008611807955140938\n",
            "Target 6:\n",
            "  MAE: 9.624209413854393e-09\n",
            "  MSE: 6.586286880124984e-16\n",
            "  R²: -4.709198073493681e-06\n",
            "Target 7:\n",
            "  MAE: 1173.4864399204766\n",
            "  MSE: 2106282.1127194623\n",
            "  R²: -0.00021509808916708728\n",
            "\n",
            "Average Scores:\n",
            "  Average MAE: 12747250892.743088\n",
            "  Average MSE: 1.1061425913593277e+22\n",
            "  Average R²: -0.016695698443680764\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Save the results \u001b[39;00m\n\u001b[32m     36\u001b[39m results = pd.DataFrame({\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m: [model_name],\n\u001b[32m     38\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m: [average_mae],\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m'\u001b[39m: [average_mse],\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mR²\u001b[39m\u001b[33m'\u001b[39m: [average_r2]\n\u001b[32m     41\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mmodel_results\u001b[49m.append(results)\n",
            "\u001b[31mNameError\u001b[39m: name 'model_results' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for each target variable\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    mae = mean_absolute_error(y[:, i], y_pred[:, i])\n",
        "    mse = mean_squared_error(y[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y[:, i], y_pred[:, i])\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"Target {i+1}:\")\n",
        "    print(f\"  MAE: {mae}\")\n",
        "    print(f\"  MSE: {mse}\")\n",
        "    print(f\"  R²: {r2}\")\n",
        "\n",
        "# Calculate average scores across all target variables\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Average MAE: {average_mae}\")\n",
        "print(f\"  Average MSE: {average_mse}\")\n",
        "print(f\"  Average R²: {average_r2}\")\n",
        "\n",
        "\n",
        "model_name = 'CatBoost'\n",
        "# Save the results \n",
        "results = pd.DataFrame({\n",
        "    'Model': [model_name],\n",
        "    'MAE': [average_mae],\n",
        "    'MSE': [average_mse],\n",
        "    'R²': [average_r2]\n",
        "})\n",
        "\n",
        "model_results.append(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[                       Model           MAE           MSE        R²\n",
              " 0  GradientBoostingRegressor  3.626702e+08  8.964580e+18  0.998653,\n",
              "            Model           MAE           MSE        R²\n",
              " 0  NeuralNetwork  1.170840e+10  1.230171e+22 -0.343252,\n",
              "                    Model           MAE           MSE       R²\n",
              " 0  RandomForestRegressor  2.533723e+09  3.961296e+21  0.86193,\n",
              "          Model           MAE           MSE        R²\n",
              " 0  Transformer  6.009404e+09  1.023610e+22  0.257705,\n",
              "                Model           MAE           MSE        R²\n",
              " 0  StackingRegressor  4.435182e+09  9.577756e+21  0.321024,\n",
              "                     Model           MAE           MSE        R²\n",
              " 0  SupportVectorRegressor  9.002861e+10  6.607267e+22 -0.492567,\n",
              "             Model           MAE           MSE       R²\n",
              " 0  MultiTaskLasso  1.002884e+10  9.094514e+21  0.57679,\n",
              "                 Model           MAE           MSE        R²\n",
              " 0  BayesianRegression  1.274725e+10  1.106143e+22 -0.016696]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all results into a single DataFrame\n",
        "final_results = pd.concat(model_results, ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "final_results.to_csv('model_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Thesis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
