{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data (replace this with actual CSV file or DataFrame)\n",
    "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
    "# Features and targets\n",
    "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
    "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
    "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, PolynomialFeatures\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling for training and testing sets\n",
    "feature_robust_scaler = RobustScaler()\n",
    "X_train_robust_scaled = feature_robust_scaler.fit_transform(X_train)\n",
    "X_test_robust_scaled = feature_robust_scaler.transform(X_test)\n",
    "\n",
    "feature_power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "X_train_power_scaled = feature_power_scaler.fit_transform(X_train)\n",
    "X_test_power_scaled = feature_power_scaler.transform(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "feature_poly_robust_scaler = RobustScaler()\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "X_train_poly_robust_scaled = feature_poly_robust_scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_robust_scaled = feature_poly_robust_scaler.transform(X_test_poly)\n",
    "\n",
    "# Target scaling for training and testing sets\n",
    "target_robust_scaler = RobustScaler()\n",
    "y_train_robust_scaled = target_robust_scaler.fit_transform(y_train)\n",
    "y_test_robust_scaled = target_robust_scaler.transform(y_test)\n",
    "\n",
    "target_power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "y_train_power_scaled = target_power_scaler.fit_transform(y_train)\n",
    "y_test_power_scaled = target_power_scaler.transform(y_test)\n",
    "\n",
    "target_multi_robust_scalers = [RobustScaler() for _ in range(y.shape[1])]\n",
    "y_train_multi_robust_scaled = np.zeros_like(y_train)\n",
    "y_test_multi_robust_scaled = np.zeros_like(y_test)\n",
    "for i in range(y.shape[1]):\n",
    "    y_train_multi_robust_scaled[:, i] = target_multi_robust_scalers[i].fit_transform(y_train[:, i].reshape(-1, 1)).ravel()\n",
    "    y_test_multi_robust_scaled[:, i] = target_multi_robust_scalers[i].transform(y_test[:, i].reshape(-1, 1)).ravel()\n",
    "\n",
    "target_multi_power_scaler = {i: PowerTransformer(method='yeo-johnson') for i in range(y.shape[1])}\n",
    "y_train_multi_power_scaled = np.zeros_like(y_train)\n",
    "y_test_multi_power_scaled = np.zeros_like(y_test)\n",
    "for i in range(y.shape[1]):\n",
    "    y_train_multi_power_scaled[:, i] = target_multi_power_scaler[i].fit_transform(y_train[:, i].reshape(-1, 1)).ravel()\n",
    "    y_test_multi_power_scaled[:, i] = target_multi_power_scaler[i].transform(y_test[:, i].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def model_evaluation(y_true, y_pred, model_name=None, debug=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model using MAE, MSE, and R² metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Actual target values\n",
    "    - y_pred: Predicted target values\n",
    "    - model_name: Name of the model (optional)\n",
    "    Returns:\n",
    "    - mae: Mean Absolute Error\n",
    "    - mse: Mean Squared Error\n",
    "    - r2: R² Score\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate evaluation metrics for each target variable\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        mse_scores.append(mse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Target {i+1}:\")\n",
    "            print(f\"  MAE: {mae}\")\n",
    "            print(f\"  MSE: {mse}\")\n",
    "            print(f\"  R²: {r2}\")\n",
    "\n",
    "    # Calculate average scores across all target variables\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Return a dictionary with overall and individual scores\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"R2\": r2,\n",
    "        \"MAE_Scores\": mae_scores,\n",
    "        \"MSE_Scores\": mse_scores,\n",
    "        \"R2_Scores\": r2_scores\n",
    "    }\n",
    "\n",
    "def print_predictions(y_pred, y, num=0):\n",
    "    np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
    "    for i in range(num):\n",
    "        print(f\"Predicted: {y_pred[i]}\")\n",
    "        print(f\"Actual:    {y[i]}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/lib/python3.12/lib-dynload/../../libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/bin/../lib/libomp.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsRegressor\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# from xgboost import XGBRegressor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLPRegressor\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# .basic is intentionally loaded as early as possible, to dlopen() lib_lightgbm.{dll,dylib,so}\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# and its dependencies as early as possible\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/basic.py:9\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Wrapper for C API of LightGBM.\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# This import causes lib_lightgbm.{dll,dylib,so} to be loaded.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# It's intentionally done here, as early as possible, to avoid issues like\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# \"libgomp.so.1: cannot allocate memory in static TLS block\" on aarch64 Linux.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# For details, see the \"cannot allocate memory in static TLS block\" entry in docs/FAQ.rst.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB  \u001b[38;5;66;03m# isort: skip\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabc\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mctypes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/libpath.py:49\u001b[39m\n\u001b[32m     47\u001b[39m     _LIB = Mock(ctypes.CDLL)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     _LIB = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcdll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_find_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/ctypes/__init__.py:460\u001b[39m, in \u001b[36mLibraryLoader.LoadLibrary\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/ctypes/__init__.py:379\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mOSError\u001b[39m: dlopen(/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/lib/python3.12/lib-dynload/../../libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/bin/../lib/libomp.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to evaluate model performance\n",
    "\n",
    "# Initialize a list to store model performance\n",
    "model_performance = []\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = MultiOutputRegressor(LinearRegression())\n",
    "linear_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_linear = linear_model.predict(X_test_robust_scaled)\n",
    "y_pred_linear_inverse = np.zeros_like(y_pred_linear)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_linear_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_linear[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_linear_inverse, \"Linear Regression\"))\n",
    "\n",
    "# Decision Tree Regressor\n",
    "decision_tree_model = MultiOutputRegressor(DecisionTreeRegressor(random_state=42))\n",
    "decision_tree_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_tree = decision_tree_model.predict(X_test_robust_scaled)\n",
    "y_pred_tree_inverse = np.zeros_like(y_pred_tree)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_tree_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_tree[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_tree_inverse, \"Decision Tree Regressor\"))\n",
    "\n",
    "# Random Forest Regressor\n",
    "random_forest_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "random_forest_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_rf = random_forest_model.predict(X_test_robust_scaled)\n",
    "y_pred_rf_inverse = np.zeros_like(y_pred_rf)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_rf_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_rf[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_rf_inverse, \"Random Forest Regressor\"))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gradient_boosting_model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=4, random_state=42))\n",
    "gradient_boosting_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_gb = gradient_boosting_model.predict(X_test_robust_scaled)\n",
    "y_pred_gb_inverse = np.zeros_like(y_pred_gb)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_gb_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_gb[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_gb_inverse, \"Gradient Boosting Regressor\"))\n",
    "\n",
    "# Support Vector Regression\n",
    "svr_model = MultiOutputRegressor(SVR(kernel='rbf', C=1.0, epsilon=0.1))\n",
    "svr_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_svr = svr_model.predict(X_test_robust_scaled)\n",
    "y_pred_svr_inverse = np.zeros_like(y_pred_svr)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_svr_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_svr[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_svr_inverse, \"Support Vector Regression\"))\n",
    "\n",
    "# K-Nearest Neighbors Regressor\n",
    "knn_model = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=5))\n",
    "knn_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_knn = knn_model.predict(X_test_robust_scaled)\n",
    "y_pred_knn_inverse = np.zeros_like(y_pred_knn)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_knn_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_knn[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_knn_inverse, \"K-Nearest Neighbors Regressor\"))\n",
    "\n",
    "# XGBoost Regressor\n",
    "# xgb_model = MultiOutputRegressor(XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=4, random_state=42))\n",
    "# xgb_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "# y_pred_xgb = xgb_model.predict(X_test_robust_scaled)\n",
    "# y_pred_xgb_inverse = np.zeros_like(y_pred_xgb)\n",
    "# for i in range(y_test.shape[1]):\n",
    "#     y_pred_xgb_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_xgb[:, i].reshape(-1, 1)).ravel()\n",
    "# model_performance.append(model_evaluation(y_test, y_pred_xgb_inverse, \"XGBoost Regressor\"))\n",
    "\n",
    "# LightGBM Regressor\n",
    "lgbm_model = MultiOutputRegressor(LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=4, random_state=42))\n",
    "lgbm_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_robust_scaled)\n",
    "y_pred_lgbm_inverse = np.zeros_like(y_pred_lgbm)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_lgbm_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_lgbm[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_lgbm_inverse, \"LightGBM Regressor\"))\n",
    "\n",
    "# Neural Network (MLP Regressor)\n",
    "mlp_model = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42))\n",
    "mlp_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_mlp = mlp_model.predict(X_test_robust_scaled)\n",
    "y_pred_mlp_inverse = np.zeros_like(y_pred_mlp)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_mlp_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_mlp[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_mlp_inverse, \"Neural Network (MLP Regressor)\"))\n",
    "\n",
    "# ElasticNet Regression\n",
    "elasticnet_model = MultiOutputRegressor(ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42))\n",
    "elasticnet_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_en = elasticnet_model.predict(X_test_robust_scaled)\n",
    "y_pred_en_inverse = np.zeros_like(y_pred_en)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_en_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_en[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_en_inverse, \"ElasticNet Regression\"))\n",
    "\n",
    "# CatBoost Regressor\n",
    "catboost_model = MultiOutputRegressor(CatBoostRegressor(iterations=500, learning_rate=0.1, depth=4, random_state=42, verbose=0))\n",
    "catboost_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_cb = catboost_model.predict(X_test_robust_scaled)\n",
    "y_pred_cb_inverse = np.zeros_like(y_pred_cb)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_cb_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_cb[:, i].reshape(-1, 1)).ravel()\n",
    "model_performance.append(model_evaluation(y_test, y_pred_cb_inverse, \"CatBoost Regressor\"))\n",
    "\n",
    "# Convert the performance list into a DataFrame for better visualization\n",
    "performance_df = pd.DataFrame(model_performance)\n",
    "print(performance_df)\n",
    "\n",
    "# Optional: Save the comparison table to a CSV file\n",
    "performance_df.to_csv(\"model_comparison.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "# prompt: create a funciton for shap analysis, and then iterate all the model, y_pred, y_test from the above models dict\n",
    "\n",
    "import shap\n",
    "\n",
    "def shap_analysis(model, X_test, model_name):\n",
    "    # Check the model type and use the appropriate explainer\n",
    "    if isinstance(model, (DecisionTreeRegressor, RandomForestRegressor, GradientBoostingRegressor, XGBRegressor, LGBMRegressor)):  \n",
    "        # Tree-based models\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    elif isinstance(model, (LinearRegression, SVR, KNeighborsRegressor)):  \n",
    "        # Linear models, SVR, and KNN\n",
    "        explainer = shap.KernelExplainer(model.predict, X_test)\n",
    "    elif isinstance(model, ElasticNet):\n",
    "        # ElasticNet\n",
    "        explainer = shap.LinearExplainer(model, X_test)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {type(model)}\")\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Plot summary of SHAP values\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n",
    "    plt.title(f\"SHAP Summary Plot - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'models' is defined as in the provided code.\n",
    "for model_data in models:\n",
    "    model = model_data[\"model\"]\n",
    "    y_pred = model_data[\"y_pred\"]\n",
    "    y_test = model_data[\"y_test\"]\n",
    "    model_name = model_data[\"model_name\"]\n",
    "\n",
    "    # Check if the model has a 'estimators_' attribute (for MultiOutputRegressor)\n",
    "    if hasattr(model, \"estimators_\"):\n",
    "        for i, estimator in enumerate(model.estimators_):\n",
    "          print(f\"SHAP analysis for {model_name}, target {i+1}\")\n",
    "          shap_analysis(estimator, X_test_robust_scaled, f\"{model_name} - Target {i+1}\")\n",
    "    else:\n",
    "        print(f\"SHAP analysis for {model_name}\")\n",
    "        shap_analysis(model, X_test_robust_scaled, model_name)\n",
    "\n",
    "\n",
    "# Sensitivity Analysis for all models\n",
    "def sensitivity_analysis(model, X_sample, feature_names, variation=0.1):\n",
    "    sensitivities = {}\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        X_varied = X_sample.copy()\n",
    "        X_varied[:, i] *= (1 + variation)  # Increase feature by 10%\n",
    "        y_pred_varied = model.predict(X_varied)\n",
    "        sensitivities[feature] = np.mean(np.abs(y_pred_varied - model.predict(X_sample)))\n",
    "    return sensitivities\n",
    "\n",
    "# Bootstrap Uncertainty Estimation for all models\n",
    "def bootstrap_uncertainty(model, X, n_bootstrap=100):\n",
    "    predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(range(X.shape[0]), size=X.shape[0], replace=True)\n",
    "        X_sample = X[indices]\n",
    "        predictions.append(model.predict(X_sample))\n",
    "    predictions = np.array(predictions)\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "    std_prediction = np.std(predictions, axis=0)\n",
    "    return mean_prediction, std_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature names\n",
    "feature_names = data.columns[:-7]\n",
    "\n",
    "# Perform analyses for all models\n",
    "for model, model_name in [\n",
    "    (linear_model, \"Linear Regression\"),\n",
    "    (decision_tree_model, \"Decision Tree Regressor\"),\n",
    "    (random_forest_model, \"Random Forest Regressor\"),\n",
    "    (gradient_boosting_model, \"Gradient Boosting Regressor\"),\n",
    "    (svr_model, \"Support Vector Regression\"),\n",
    "    (knn_model, \"K-Nearest Neighbors Regressor\"),\n",
    "    (xgb_model, \"XGBoost Regressor\"),\n",
    "    (lgbm_model, \"LightGBM Regressor\"),\n",
    "    (mlp_model, \"Neural Network (MLP Regressor)\"),\n",
    "    (elasticnet_model, \"ElasticNet Regression\"),\n",
    "    (catboost_model, \"CatBoost Regressor\")\n",
    "]:\n",
    "    print(f\"Performing SHAP Analysis for {model_name}...\")\n",
    "    shap_analysis(model, X_test_robust_scaled, feature_names, model_name)\n",
    "\n",
    "    print(f\"Performing Sensitivity Analysis for {model_name}...\")\n",
    "    sensitivity = sensitivity_analysis(model, X_test_robust_scaled, feature_names)\n",
    "    print(f\"Sensitivity Analysis ({model_name}):\", sensitivity)\n",
    "\n",
    "    print(f\"Performing Bootstrap Uncertainty Estimation for {model_name}...\")\n",
    "    mean_pred, std_pred = bootstrap_uncertainty(model, X_test_robust_scaled)\n",
    "    print(f\"Mean Prediction ({model_name}):\", mean_pred)\n",
    "    print(f\"Uncertainty (Standard Deviation):\", std_pred)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
