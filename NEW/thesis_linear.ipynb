{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1045, 15)\n",
      "Shape of y: (1045, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load Data (replace this with actual CSV file or DataFrame)\n",
    "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
    "# Features and targets\n",
    "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
    "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
    "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Split first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scalers_X = []\n",
    "X_train_scaled = np.zeros_like(X_train)\n",
    "X_test_scaled = np.zeros_like(X_test)\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled[:, i] = scaler.fit_transform(X_train[:, i].reshape(-1, 1)).flatten()\n",
    "    X_test_scaled[:, i] = scaler.transform(X_test[:, i].reshape(-1, 1)).flatten()\n",
    "    scalers_X.append(scaler)\n",
    "\n",
    "# Scale y column-wise\n",
    "scalers_y = []\n",
    "y_train_scaled = np.zeros_like(y_train)\n",
    "y_test_scaled = np.zeros_like(y_test)\n",
    "\n",
    "for i in range(y.shape[1]):\n",
    "    scaler = MinMaxScaler()\n",
    "    y_train_scaled[:, i] = scaler.fit_transform(y_train[:, i].reshape(-1, 1)).flatten()\n",
    "    y_test_scaled[:, i] = scaler.transform(y_test[:, i].reshape(-1, 1)).flatten()\n",
    "    scalers_y.append(scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MAE: 8085212901.9415\n",
      "Elastic Net MAE: 11471384065.1735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data (Assume X, y are already loaded)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler_X, scaler_y = StandardScaler(), StandardScaler()\n",
    "X_train_scaled, X_test_scaled = scaler_X.fit_transform(X_train), scaler_X.transform(X_test)\n",
    "y_train_scaled, y_test_scaled = scaler_y.fit_transform(y_train), scaler_y.transform(y_test)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge = MultiOutputRegressor(Ridge(alpha=1.0)).fit(X_train_scaled, y_train_scaled)\n",
    "y_pred_ridge = scaler_y.inverse_transform(ridge.predict(X_test_scaled))\n",
    "\n",
    "# Elastic Net\n",
    "elastic_net = MultiOutputRegressor(ElasticNet(alpha=1.0, l1_ratio=0.5)).fit(X_train_scaled, y_train_scaled)\n",
    "y_pred_elastic = scaler_y.inverse_transform(elastic_net.predict(X_test_scaled))\n",
    "\n",
    "# Evaluation\n",
    "ridge_mae = mean_absolute_error(y_test, y_pred_ridge)\n",
    "elastic_mae = mean_absolute_error(y_test, y_pred_elastic)\n",
    "\n",
    "print(f\"Ridge MAE: {ridge_mae:.4f}\")\n",
    "print(f\"Elastic Net MAE: {elastic_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [ 6.57297489e+10  7.57492483e+00  3.22094676e+02 -3.39824954e-04  1.10836199e-01 -6.88994820e-10  6.82178781e+03]\n",
      "Actual:    [ 5.75659234e+10  3.79152653e-02  1.01572435e+02  3.00662118e-05  4.87692269e-10 -6.17503512e-13  7.33000000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 1.77487235e+11  1.60687483e-01  2.89085891e+01  1.36927952e-03  3.57815946e-02 -6.42206148e-09  6.40646991e+03]\n",
      "Actual:    [9.65571615e+10 5.65677431e-01 1.46347462e-03 7.18733615e-04 7.40538530e-10 2.87408973e-10 7.10000000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 1.11068591e+10 -9.61700403e-01  2.45374597e+01  2.33363513e-03 -2.62243003e-03  1.12290208e-09  4.96763542e+03]\n",
      "Actual:    [3.06869106e+10 3.47867300e-04 1.45706883e-06 3.18686247e-03 1.43839504e-10 7.08191652e-10 5.28000000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 3.46876925e+10  1.42984631e+01 -3.00070021e+01 -4.24178273e-04 -5.55018429e-02 -2.36000554e-08  8.45296280e+03]\n",
      "Actual:    [ 1.23707914e+11  6.97810465e+01  1.79492512e+02  1.12323008e-05  1.00493513e-01 -3.93328375e-08  8.15750000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 7.28789602e+10 -1.75392881e+00 -1.80585024e+01  2.43831594e-03 -4.38089361e-02  7.17896788e-09  5.54120764e+03]\n",
      "Actual:    [3.35672219e+10 6.05604456e-04 1.98747641e-06 3.50214417e-03 1.30390531e-10 7.78254204e-10 5.43000000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 4.46687829e+10 -2.52701830e+00 -3.24523419e+01  2.53071196e-03 -6.02052711e-02  5.48475417e-09  4.93066812e+03]\n",
      "Actual:    [3.23255507e+10 2.39823538e-04 1.48023086e-06 3.86142433e-03 1.17606141e-10 8.58094281e-10 5.35500000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 4.30908598e+10  2.86192979e-01 -3.47812689e+00  8.38303798e-04 -1.69245232e-02  3.30155425e-09  4.86867923e+03]\n",
      "Actual:    [4.11522576e+10 1.56988231e-03 6.76820965e-06 6.64657976e-04 2.57582774e-10 5.27506131e-10 4.99000000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 4.50079473e+10 -2.75045908e+00  5.76523427e+01  1.07438247e-03  1.76220711e-02 -4.14799395e-09  6.49649469e+03]\n",
      "Actual:    [4.13876465e+10 6.42460659e-02 1.19116498e-03 8.14246249e-04 2.09023063e-10 6.46201526e-10 5.72000000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [ 1.97365718e+11 -5.54174526e-01  1.78930667e-01  2.47254366e-03 -2.57502498e-02  4.65128430e-09  4.76322046e+03]\n",
      "Actual:    [3.30791681e+11 9.04015507e-04 4.70102981e-06 3.54087060e-03 1.58210984e-10 1.41634820e-09 4.92500000e+03]\n",
      "--------------------------------------------------\n",
      "Predicted: [5.93351375e+10 4.62540895e+00 8.43021603e+01 9.02903343e-04 1.08029674e-01 9.60829327e-10 6.78677428e+03]\n",
      "Actual:    [5.87128783e+10 6.86328756e-03 1.06539952e-06 2.38086425e-04 1.89994777e-09 5.29079042e-11 7.92000000e+03]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = ridge.predict(X_test_scaled)\n",
    "\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
    "for i in range(10):\n",
    "    print(f\"Predicted: {y_pred[i]}\")\n",
    "    print(f\"Actual:    {y_test[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <54A1AE05-1E14-3DA2-A8D0-062134694298> /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/lib/python3.12/lib-dynload/../../libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/bin/../lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Define and train the model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/core.py:295\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/core.py:257\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    256\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    258\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    266\u001b[39m \n\u001b[32m    267\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    268\u001b[39m \n\u001b[32m    269\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    271\u001b[39m         )\n\u001b[32m    272\u001b[39m     _register_log_callback(lib)\n\u001b[32m    274\u001b[39m     libver = _lib_version(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <54A1AE05-1E14-3DA2-A8D0-062134694298> /opt/anaconda3/envs/Thesis/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/lib/python3.12/lib-dynload/../../libomp.dylib' (no such file), '/opt/anaconda3/envs/Thesis/bin/../lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define and train the model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
