{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data (replace this with actual CSV file or DataFrame)\n",
    "data = pd.read_csv('merged_properties.csv')  # Replace 'your_file.csv' with your actual file path\n",
    "# Features and targets\n",
    "# X = data.drop(columns=['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']).values\n",
    "X = data[['vf', 'c55e', 'e15e', 'q15e', 'ϵ11e', 'μ11e', 'α11e', 'ρe', 'c55f', 'e15f', 'q15f', 'ϵ11f', 'μ11f', 'α11f', 'ρf']].values\n",
    "y = data[['c44', 'e15', 'q15', 'μ11', 'ϵ11', 'α11', 'ρ']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, PolynomialFeatures\n",
    "\n",
    "# Feature scaling\n",
    "feature_robust_scaler = RobustScaler()\n",
    "X_robust_scaled = feature_robust_scaler.fit_transform(X)\n",
    "\n",
    "feature_power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "X_power_scaled = feature_power_scaler.fit_transform(X)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "feature_poly_robust_scaler = RobustScaler()\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_poly_robust_scaled = feature_poly_robust_scaler.fit_transform(X_poly)\n",
    "\n",
    "\n",
    "# Target Scaling\n",
    "target_robust_scaler = RobustScaler()\n",
    "y_robust = target_robust_scaler.fit_transform(y)\n",
    "\n",
    "target_power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "y_power_scaled = target_power_scaler.fit_transform(y)\n",
    "\n",
    "target_multi_robust_scalers = [RobustScaler() for _ in range(y.shape[1])]\n",
    "y_multi_robust_scaled = np.zeros_like(y)\n",
    "for i in range(y.shape[1]):\n",
    "    y_multi_robust_scaled[:, i] = target_multi_robust_scalers[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n",
    "\n",
    "target_multi_power_scaler = {i: PowerTransformer(method='yeo-johnson') for i in range(y.shape[1])}\n",
    "y_multi_power_scaled = np.zeros_like(y)\n",
    "for i in range(y.shape[1]):\n",
    "    y_multi_power_scaled[:, i] = target_multi_power_scaler[i].fit_transform(y[:, i].reshape(-1, 1)).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, PolynomialFeatures\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling for training and testing sets\n",
    "feature_robust_scaler = RobustScaler()\n",
    "X_train_robust_scaled = feature_robust_scaler.fit_transform(X_train)\n",
    "X_test_robust_scaled = feature_robust_scaler.transform(X_test)\n",
    "\n",
    "feature_power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "X_train_power_scaled = feature_power_scaler.fit_transform(X_train)\n",
    "X_test_power_scaled = feature_power_scaler.transform(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "feature_poly_robust_scaler = RobustScaler()\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "X_train_poly_robust_scaled = feature_poly_robust_scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_robust_scaled = feature_poly_robust_scaler.transform(X_test_poly)\n",
    "\n",
    "# Target scaling for training and testing sets\n",
    "target_robust_scaler = RobustScaler()\n",
    "y_train_robust_scaled = target_robust_scaler.fit_transform(y_train)\n",
    "y_test_robust_scaled = target_robust_scaler.transform(y_test)\n",
    "\n",
    "target_power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "y_train_power_scaled = target_power_scaler.fit_transform(y_train)\n",
    "y_test_power_scaled = target_power_scaler.transform(y_test)\n",
    "\n",
    "target_multi_robust_scalers = [RobustScaler() for _ in range(y.shape[1])]\n",
    "y_train_multi_robust_scaled = np.zeros_like(y_train)\n",
    "y_test_multi_robust_scaled = np.zeros_like(y_test)\n",
    "for i in range(y.shape[1]):\n",
    "    y_train_multi_robust_scaled[:, i] = target_multi_robust_scalers[i].fit_transform(y_train[:, i].reshape(-1, 1)).ravel()\n",
    "    y_test_multi_robust_scaled[:, i] = target_multi_robust_scalers[i].transform(y_test[:, i].reshape(-1, 1)).ravel()\n",
    "\n",
    "target_multi_power_scaler = {i: PowerTransformer(method='yeo-johnson') for i in range(y.shape[1])}\n",
    "y_train_multi_power_scaled = np.zeros_like(y_train)\n",
    "y_test_multi_power_scaled = np.zeros_like(y_test)\n",
    "for i in range(y.shape[1]):\n",
    "    y_train_multi_power_scaled[:, i] = target_multi_power_scaler[i].fit_transform(y_train[:, i].reshape(-1, 1)).ravel()\n",
    "    y_test_multi_power_scaled[:, i] = target_multi_power_scaler[i].transform(y_test[:, i].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def model_evaluation(y_true, y_pred, model_name=None, debug=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model using MAE, MSE, and R² metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Actual target values\n",
    "    - y_pred: Predicted target values\n",
    "    - model_name: Name of the model (optional)\n",
    "    Returns:\n",
    "    - mae: Mean Absolute Error\n",
    "    - mse: Mean Squared Error\n",
    "    - r2: R² Score\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate evaluation metrics for each target variable\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    if debug:\n",
    "        for i in range(y_true.shape[1]):\n",
    "            mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "            mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "            r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "            mae_scores.append(mae)\n",
    "            mse_scores.append(mse)\n",
    "            r2_scores.append(r2)\n",
    "\n",
    "            print(f\"Target {i+1}:\")\n",
    "            print(f\"  MAE: {mae}\")\n",
    "            print(f\"  MSE: {mse}\")\n",
    "            print(f\"  R²: {r2}\")\n",
    "\n",
    "    # Calculate average scores across all target variables\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    return {\n",
    "        \"Model\": model_name, \"MAE\": mae, \"MSE\": mse, \"R2\": r2\n",
    "    }\n",
    "\n",
    "def print_predictions(y_pred, y, num=0):\n",
    "    np.set_printoptions(linewidth=np.inf)  # Set the print options to avoid line breaks\n",
    "    for i in range(num):\n",
    "        print(f\"Predicted: {y_pred[i]}\")\n",
    "        print(f\"Actual:    {y[i]}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores:\n",
      "  Model: Linear Regression\n",
      "  Average MAE: 9462221827.06768\n",
      "  Average MSE: 1.0566172586499425e+22\n",
      "  Average R²: 0.25785807270131944\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Scores:\n",
      "  Model: Decision Tree Regressor\n",
      "  Average MAE: 336403592.679377\n",
      "  Average MSE: 2.2266554471050408e+19\n",
      "  Average R²: 0.9912597305466812\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Scores:\n",
      "  Model: Random Forest Regressor\n",
      "  Average MAE: 1793554839.0025222\n",
      "  Average MSE: 2.2505204451944689e+21\n",
      "  Average R²: 0.9276987351377376\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Scores:\n",
      "  Model: Gradient Boosting Regressor\n",
      "  Average MAE: 502529528.06820476\n",
      "  Average MSE: 1.7807977793253884e+19\n",
      "  Average R²: 0.9929411331266785\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = MultiOutputRegressor(LinearRegression())\n",
    "linear_model.fit(X_robust_scaled, y_multi_power_scaled)\n",
    "y_pred_linear = linear_model.predict(X_robust_scaled)\n",
    "y_pred_linear_inverse = np.zeros_like(y_pred_linear)\n",
    "for i in range(y.shape[1]):\n",
    "    y_pred_linear_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_linear[:, i].reshape(-1, 1)).ravel()\n",
    "print_predictions(y, y_pred_linear_inverse)\n",
    "result_linear = pd.DataFrame(model_evaluation(y, y_pred_linear_inverse, model_name='Linear Regression'))\n",
    "\n",
    "# Decision Tree Regressor\n",
    "decision_tree_model = MultiOutputRegressor(DecisionTreeRegressor(random_state=42))\n",
    "decision_tree_model.fit(X_robust_scaled, y_multi_power_scaled)\n",
    "y_pred_tree = decision_tree_model.predict(X_robust_scaled)\n",
    "y_pred_tree_inverse = np.zeros_like(y_pred_tree)\n",
    "for i in range(y.shape[1]):\n",
    "    y_pred_tree_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_tree[:, i].reshape(-1, 1)).ravel()\n",
    "print_predictions(y, y_pred_tree_inverse)\n",
    "result_tree = pd.DataFrame(model_evaluation(y, y_pred_tree_inverse, model_name='Decision Tree Regressor'))\n",
    "\n",
    "# Random Forest Regressor\n",
    "random_forest_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "random_forest_model.fit(X_robust_scaled, y_multi_power_scaled)\n",
    "y_pred_rf = random_forest_model.predict(X_robust_scaled)\n",
    "y_pred_rf_inverse = np.zeros_like(y_pred_rf)\n",
    "for i in range(y.shape[1]):\n",
    "    y_pred_rf_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_rf[:, i].reshape(-1, 1)).ravel()\n",
    "print_predictions(y, y_pred_rf_inverse)\n",
    "result_rf = pd.DataFrame(model_evaluation(y, y_pred_rf_inverse, model_name='Random Forest Regressor'))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gradient_boosting_model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42))\n",
    "gradient_boosting_model.fit(X_robust_scaled, y_multi_power_scaled)\n",
    "y_pred_gb = gradient_boosting_model.predict(X_robust_scaled)\n",
    "y_pred_gb_inverse = np.zeros_like(y_pred_gb)\n",
    "for i in range(y.shape[1]):\n",
    "    y_pred_gb_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_gb[:, i].reshape(-1, 1)).ravel()\n",
    "print_predictions(y, y_pred_gb_inverse)\n",
    "result_gb = pd.DataFrame(model_evaluation(y, y_pred_gb_inverse, model_name='Gradient Boosting Regressor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores:\n",
      "  Model: Linear Regression\n",
      "  Average MAE: 9299407598.948652\n",
      "  Average MSE: 7.217289587774969e+21\n",
      "  Average R²: 0.26545276520420286\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Scores:\n",
      "  Model: Decision Tree Regressor\n",
      "  Average MAE: 4227153307.7195926\n",
      "  Average MSE: 1.0916194733214086e+22\n",
      "  Average R²: 0.4594239423832113\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Scores:\n",
      "  Model: Random Forest Regressor\n",
      "  Average MAE: 2383434685.3320704\n",
      "  Average MSE: 2.3522872233063639e+21\n",
      "  Average R²: 0.768215331241982\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Scores:\n",
      "  Model: Gradient Boosting Regressor\n",
      "  Average MAE: 2480369773.3216805\n",
      "  Average MSE: 1.8087715797271097e+21\n",
      "  Average R²: 0.8400063846900897\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': ['Gradient Boosting Regressor'],\n",
       " 'MAE': [2480369773.3216805],\n",
       " 'MSE': [1.8087715797271097e+21],\n",
       " 'R²': [0.8400063846900897]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to evaluate model performance\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = MultiOutputRegressor(LinearRegression())\n",
    "linear_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_linear = linear_model.predict(X_test_robust_scaled)\n",
    "y_pred_linear_inverse = np.zeros_like(y_pred_linear)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_linear_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_linear[:, i].reshape(-1, 1)).ravel()\n",
    "model_evaluation(y_test, y_pred_linear_inverse, \"Linear Regression\")\n",
    "\n",
    "# Decision Tree Regressor\n",
    "decision_tree_model = MultiOutputRegressor(DecisionTreeRegressor(random_state=42))\n",
    "decision_tree_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_tree = decision_tree_model.predict(X_test_robust_scaled)\n",
    "y_pred_tree_inverse = np.zeros_like(y_pred_tree)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_tree_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_tree[:, i].reshape(-1, 1)).ravel()\n",
    "model_evaluation(y_test, y_pred_tree_inverse, \"Decision Tree Regressor\")\n",
    "\n",
    "# Random Forest Regressor\n",
    "random_forest_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "random_forest_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_rf = random_forest_model.predict(X_test_robust_scaled)\n",
    "y_pred_rf_inverse = np.zeros_like(y_pred_rf)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_rf_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_rf[:, i].reshape(-1, 1)).ravel()\n",
    "model_evaluation(y_test, y_pred_rf_inverse, \"Random Forest Regressor\")\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gradient_boosting_model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=4, random_state=42))\n",
    "gradient_boosting_model.fit(X_train_robust_scaled, y_train_multi_power_scaled)\n",
    "y_pred_gb = gradient_boosting_model.predict(X_test_robust_scaled)\n",
    "y_pred_gb_inverse = np.zeros_like(y_pred_gb)\n",
    "for i in range(y_test.shape[1]):\n",
    "    y_pred_gb_inverse[:, i] = target_multi_power_scaler[i].inverse_transform(y_pred_gb[:, i].reshape(-1, 1)).ravel()\n",
    "model_evaluation(y_test, y_pred_gb_inverse, \"Gradient Boosting Regressor\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
